{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "70ac1cbe-7cba-44da-9804-9f87ae391ca6",
   "metadata": {},
   "source": [
    "# Traffic Element Object Detection"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d355289b-93c5-4ab2-9a56-0f1282de7e5c",
   "metadata": {},
   "source": [
    "### RTDETR for Object Detection\n",
    "\n",
    "Real Time DEtection TRansformer is recently released SOTA model that performs object detection in real time and surpasses YOLOV8 in performance. In this notebook, we explore RTDETR for traffic element detection.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b52cf04c-d670-48f1-ae72-7301a1f77abb",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "!pip install torch torchvision transformers "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "591240d4-c109-4089-a168-a1180ff05ea7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import requests\n",
    "from PIL import Image\n",
    "from transformers import RTDetrForObjectDetection, RTDetrImageProcessor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "fcfadd09-01f9-463f-bc9d-4ab54bdaf461",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sofa: 0.97 [0.14, 0.38, 640.13, 476.21]\n",
      "cat: 0.96 [343.38, 24.28, 640.14, 371.5]\n",
      "cat: 0.96 [13.23, 54.18, 318.98, 472.22]\n",
      "remote: 0.95 [40.11, 73.44, 175.96, 118.48]\n",
      "remote: 0.92 [333.73, 76.58, 369.97, 186.99]\n"
     ]
    }
   ],
   "source": [
    "url = 'http://images.cocodataset.org/val2017/000000039769.jpg' \n",
    "image = Image.open(requests.get(url, stream=True).raw)\n",
    "\n",
    "image_processor = RTDetrImageProcessor.from_pretrained(\"PekingU/rtdetr_r50vd\")\n",
    "model = RTDetrForObjectDetection.from_pretrained(\"PekingU/rtdetr_r50vd\")\n",
    "\n",
    "inputs = image_processor(images=image, return_tensors=\"pt\")\n",
    "\n",
    "with torch.no_grad():\n",
    "    outputs = model(**inputs)\n",
    "\n",
    "results = image_processor.post_process_object_detection(outputs, target_sizes=torch.tensor([image.size[::-1]]), threshold=0.3)\n",
    "\n",
    "for result in results:\n",
    "    for score, label_id, box in zip(result[\"scores\"], result[\"labels\"], result[\"boxes\"]):\n",
    "        score, label = score.item(), label_id.item()\n",
    "        box = [round(i, 2) for i in box.tolist()]\n",
    "        print(f\"{model.config.id2label[label]}: {score:.2f} {box}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c93ca034-5999-4f0a-8f3d-8d6cb5c763a4",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
